{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2 \n",
    "import scipy.io as sio\n",
    "import scipy.ndimage\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/'\n",
    "output_path = '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Load high-resolution data generated from MATLAB code\n",
    "hr_files = sorted(glob.glob('/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/matlab_data/data*'))\n",
    "\n",
    "high_res_data = []\n",
    "for file in hr_files:\n",
    "    mat_data = sio.loadmat(file)\n",
    "    # Extract vorticity field 'omg' as mentioned in the paper\n",
    "    high_res_data.append(mat_data['omg'])\n",
    "    \n",
    "high_res_data = np.array(high_res_data)  # Shape: [n_samples, 128, 128]\n",
    "print(high_res_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def average_downsample(data, target_size=(16, 16)):\n",
    "    \"\"\"Perform average downsampling on the input data\"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    low_res_data = np.zeros((n_samples, target_size[0], target_size[1]))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Reshape to perform average pooling\n",
    "        h, w = data[i].shape\n",
    "        pool_size = (h // target_size[0], w // target_size[1])\n",
    "        reshaped = data[i].reshape(target_size[0], pool_size[0], \n",
    "                                  target_size[1], pool_size[1])\n",
    "        low_res_data[i] = reshaped.mean(axis=(1, 3))\n",
    "    \n",
    "    return low_res_data\n",
    "\n",
    "# Generate low-resolution data\n",
    "# low_res_data_8x8 = average_downsample(high_res_data, target_size=(8, 8))\n",
    "low_res_data_16x16 = average_downsample(high_res_data, target_size=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 204, Validation: 26, Test: 26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: Train (80%) and Temp (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    low_res_data_16x16, high_res_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Validation (10%) and Test (10%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Check the sizes\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciton for bicubic upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicubic_upsample(data, target_size=(128, 128)):\n",
    "    \"\"\"Perform bicubic interpolation to upsample low-resolution data.\"\"\"\n",
    "    upsampled_data = np.zeros((data.shape[0], target_size[0], target_size[1]))\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        upsampled_data[i] = scipy.ndimage.zoom(data[i], \n",
    "                                               (target_size[0]/data.shape[1], target_size[1]/data.shape[2]), \n",
    "                                               order=3)  # Bicubic interpolation\n",
    "    \n",
    "    return upsampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply bicubic upsampling to the LR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bicubic Upsampled Training Data: (204, 128, 128)\n",
      "Bicubic Upsampled Validation Data: (26, 128, 128)\n",
      "Bicubic Upsampled Test Data: (26, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Upsample from 8x8 to 128x128 using bicubic interpolation\n",
    "upsampled_train_16x16 = bicubic_upsample(X_train, target_size=(128, 128))\n",
    "upsampled_val_16x16 = bicubic_upsample(X_val, target_size=(128, 128))\n",
    "upsampled_test_16x16 = bicubic_upsample(X_test, target_size = (128, 128))\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Bicubic Upsampled Training Data: {upsampled_train_16x16.shape}\")\n",
    "print(f\"Bicubic Upsampled Validation Data: {upsampled_val_16x16.shape}\")\n",
    "print(f\"Bicubic Upsampled Test Data: {upsampled_test_16x16.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved upsampled datasets in /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/bicubic_upsampled_16x16/\n"
     ]
    }
   ],
   "source": [
    "# Define save paths\n",
    "curr_dir = '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/'\n",
    "bicubic_save_dir = curr_dir + 'bicubic_upsampled_16x16/'\n",
    "os.makedirs(bicubic_save_dir, exist_ok=True)\n",
    "\n",
    "# Save the data\n",
    "np.save(bicubic_save_dir + 'train.npy', upsampled_train_16x16)\n",
    "np.save(bicubic_save_dir + 'val.npy', upsampled_val_16x16)\n",
    "\n",
    "print(f\"Saved upsampled datasets in {bicubic_save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_and_save_samples(low_res_samples, high_res_samples, upsampled_samples=None, num_samples=5, dataset_type=\"Training\", save_dir=\"visualizations\", save=True):\n",
    "    \"\"\"\n",
    "    Visualizes and optionally saves low-res vs upsampled (if provided) vs high-res samples.\n",
    "\n",
    "    Parameters:\n",
    "        - low_res_samples: Array of low-resolution images.\n",
    "        - high_res_samples: Array of high-resolution images.\n",
    "        - upsampled_samples: (Optional) Array of upsampled images.\n",
    "        - num_samples: Number of samples to visualize.\n",
    "        - dataset_type: \"Training\" or \"Validation\".\n",
    "        - save_dir: Directory to save the visualization images.\n",
    "        - save: Whether to save the images (default: True).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure save directory exists\n",
    "\n",
    "    indices = np.random.choice(len(low_res_samples), num_samples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        num_cols = 3 if upsampled_samples is not None else 2  # Determine columns based on upsampling availability\n",
    "        fig, axes = plt.subplots(1, num_cols, figsize=(15, 5))\n",
    "        fig.suptitle(f\"{dataset_type} Sample {i+1}\", fontsize=14)\n",
    "\n",
    "        # Low-res Image\n",
    "        axes[0].imshow(low_res_samples[idx], cmap='inferno')\n",
    "        axes[0].set_title(f\"Low-Res {low_res_samples[idx].shape}\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Upsampled Image (if provided)\n",
    "        if upsampled_samples is not None:\n",
    "            axes[1].imshow(upsampled_samples[idx], cmap='inferno')\n",
    "            axes[1].set_title(f\"Upsampled {upsampled_samples[idx].shape}\")\n",
    "            axes[1].axis('off')\n",
    "\n",
    "        # High-res Image\n",
    "        axes[-1].imshow(high_res_samples[idx], cmap='inferno')\n",
    "        axes[-1].set_title(f\"High-Res {high_res_samples[idx].shape}\")\n",
    "        axes[-1].axis('off')\n",
    "\n",
    "        # Save or show plot\n",
    "        if save:\n",
    "            save_path = os.path.join(save_dir, f\"{dataset_type.lower()}_sample_{i+1}.png\")\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        else:\n",
    "            pass\n",
    "            # plt.show()\n",
    "\n",
    "        # print(f\"Saved {dataset_type} Sample {i+1} to {save_dir}\") if save else None\n",
    "\n",
    "    print(f\"Visualization completed for {num_samples} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Test Sample 1 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 2 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 3 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 4 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 5 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 6 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 7 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 8 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 9 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 10 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 11 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 12 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 13 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 14 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 15 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 16 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 17 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 18 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 19 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 20 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 21 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 22 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 23 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 24 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 25 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Saved Test Sample 26 to /home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/\n",
      "Visualization completed for 26 samples.\n"
     ]
    }
   ],
   "source": [
    "# Visualize bicubic upsampled results\n",
    "save_dir = '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/outputs/bicubic/visualizations_16x16/all/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_save_samples(X_train, y_train, upsampled_samples=upsampled_train_16x16, num_samples=len(X_train), dataset_type=\"Training\", save_dir=save_dir)\n",
    "visualize_and_save_samples(X_val, y_val, upsampled_samples=upsampled_val_16x16, num_samples=len(X_val), dataset_type=\"Validation\", save_dir=save_dir)\n",
    "visualize_and_save_samples(X_test, y_test, upsampled_samples=upsampled_test_16x16, num_samples=len(X_test), dataset_type=\"Test\", save_dir=save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
