{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Data Generation/Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Load high-resolution data generated from MATLAB code\n",
    "hr_files = sorted(glob.glob('/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/matlab_data/data*'))\n",
    "\n",
    "high_res_data = []\n",
    "for file in hr_files:\n",
    "    mat_data = sio.loadmat(file)\n",
    "    # Extract vorticity field 'omg' as mentioned in the paper\n",
    "    high_res_data.append(mat_data['omg'])\n",
    "    \n",
    "high_res_data = np.array(high_res_data)  # Shape: [n_samples, 128, 128]\n",
    "print(high_res_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Low-Resolution Data using Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def average_downsample(data, target_size=(16, 16)):\n",
    "    \"\"\"Perform average downsampling on the input data\"\"\"\n",
    "    n_samples = data.shape[0]\n",
    "    low_res_data = np.zeros((n_samples, target_size[0], target_size[1]))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Reshape to perform average pooling\n",
    "        h, w = data[i].shape\n",
    "        pool_size = (h // target_size[0], w // target_size[1])\n",
    "        reshaped = data[i].reshape(target_size[0], pool_size[0], \n",
    "                                  target_size[1], pool_size[1])\n",
    "        low_res_data[i] = reshaped.mean(axis=(1, 3))\n",
    "    \n",
    "    return low_res_data\n",
    "\n",
    "# Generate low-resolution data\n",
    "low_res_data_8x8 = average_downsample(high_res_data, target_size=(8, 8))\n",
    "# low_res_data_16x16 = average_downsample(high_res_data, target_size=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the shapes of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# print(low_res_data_16x16.shape)\n",
    "print(low_res_data_8x8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (80% train, 20% validation as commonly used)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    low_res_data_8x8, high_res_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "curr_dir = '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/'\n",
    "\n",
    "# Save the processed data\n",
    "\n",
    "np.save(curr_dir + 'high_res/train.npy', y_train)\n",
    "np.save(curr_dir + 'high_res/val.npy', y_val)\n",
    "np.save(curr_dir + 'low_res_8x8/train.npy', X_train)\n",
    "np.save(curr_dir + 'low_res_8x8/val.npy', X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the shapes of the flowfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 204 low-res samples, shape: (204, 8, 8)\n",
      "Validation data: 52 low-res samples, shape: (52, 8, 8)\n",
      "Training targets: 204 high-res samples, shape: (204, 128, 128)\n",
      "Validation targets: 52 high-res samples, shape: (52, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved data\n",
    "X_train = np.load(curr_dir + 'low_res_8x8/train.npy')\n",
    "X_val = np.load(curr_dir + 'low_res_8x8/val.npy')\n",
    "y_train = np.load(curr_dir + 'high_res/train.npy')\n",
    "y_val = np.load(curr_dir + 'high_res/val.npy')\n",
    "\n",
    "# Print shapes to confirm dimensions\n",
    "print(f\"Training data: {len(X_train)} low-res samples, shape: {X_train.shape}\")\n",
    "print(f\"Validation data: {len(X_val)} low-res samples, shape: {X_val.shape}\")\n",
    "print(f\"Training targets: {len(y_train)} high-res samples, shape: {y_train.shape}\")\n",
    "print(f\"Validation targets: {len(y_val)} high-res samples, shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the flowfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/data_visualizations/vis_8x8_/\n",
      "Saved 204 samples in '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/data_visualizations/vis_8x8_/' directory.\n",
      "Saved 52 samples in '/home/diya/Projects/super_resolution/flow_super_resolution/dataset/train_data_ml_spatio-temporal_fukami_paper/data_HR/data_visualizations/vis_8x8_/' directory.\n"
     ]
    }
   ],
   "source": [
    "def visualize_and_save_samples(low_res_samples, high_res_samples, num_samples=5, dataset_type=\"Training\", save_dir=\"visualizations\"):\n",
    "    \"\"\"\n",
    "    Visualizes and saves low-res vs high-res samples.\n",
    "\n",
    "    Parameters:\n",
    "        - low_res_samples: List/array of low-resolution images.\n",
    "        - high_res_samples: List/array of high-resolution images.\n",
    "        - num_samples: Number of samples to visualize.\n",
    "        - dataset_type: \"Training\" or \"Validation\".\n",
    "        - save_dir: Directory to save the visualization images.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Create directory if not exists\n",
    "\n",
    "    indices = np.random.choice(len(low_res_samples), num_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        fig.suptitle(f\"{dataset_type} Sample {i+1}: Low-res vs High-res\", fontsize=14)\n",
    "\n",
    "        # Low-res Image\n",
    "        low_res_img = low_res_samples[idx]\n",
    "        axes[0].imshow(low_res_img, cmap='inferno')\n",
    "        axes[0].set_title(f\"Low-Res {low_res_img.shape}\")\n",
    "        axes[0].set_xlabel(\"X-axis\")\n",
    "        axes[0].set_ylabel(\"Y-axis\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # High-res Image\n",
    "        high_res_img = high_res_samples[idx]\n",
    "        axes[1].imshow(high_res_img, cmap='inferno')\n",
    "        axes[1].set_title(f\"High-Res {high_res_img.shape}\")\n",
    "        axes[1].set_xlabel(\"X-axis\")\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # Save the figure\n",
    "        save_path = os.path.join(save_dir, f\"{dataset_type.lower()}_sample_{i+1}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close(fig)  \n",
    "\n",
    "    print(f\"Saved {num_samples} samples in '{save_dir}' directory.\")\n",
    "\n",
    "curr_dir = curr_dir\n",
    "save_dir = curr_dir + 'data_visualizations/vis_8x8/'\n",
    "# check if save_dir exists \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "print(save_dir)\n",
    "\n",
    "# Visualize training samples\n",
    "train_fig = visualize_and_save_samples(X_train, y_train, num_samples=len(X_train), dataset_type=\"Training\", save_dir = save_dir)\n",
    "# plt.savefig('train_samples_visualization.png', dpi=150, bbox_inches='tight')\n",
    "\n",
    "# Visualize validation samples\n",
    "val_fig = visualize_and_save_samples(X_val, y_val, num_samples=len(X_val), dataset_type=\"Validation\", save_dir = save_dir)\n",
    "# plt.savefig('validation_samples_visualization.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
